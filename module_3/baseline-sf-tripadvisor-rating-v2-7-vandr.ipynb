{"cells":[{"metadata":{},"cell_type":"markdown","source":"Итоговое задание Виктора Андрийчука по Проекту 3. О вкусной и здоровой пище (SF-DST-14)\n\nЮнит 3. Введение в машинное обучение (отредактирован 12.07.2020)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n**По ходу задачи:**\n* Прокачаем работу с pandas\n* Научимся работать с Kaggle Notebooks\n* Поймем как делать предобработку различных данных\n* Научимся работать с пропущенными данными (Nan)\n* Познакомимся с различными видами кодирования признаков\n* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n* И совсем немного затронем ML\n* И многое другое...   \n\n\n\n### И самое важное, все это вы сможете сделать самостоятельно!\n\n*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \nВы можете использовать его как основу для построения своего решения.\n\n> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \nТакже baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n\nВ контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."},{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\nimport re\nimport datetime\n\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42\nCURRENT_DATE = pd.to_datetime('12/07/2020')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{},"cell_type":"markdown","source":"# Обработка"},{"metadata":{},"cell_type":"markdown","source":"## 1. Обработка NAN \nУ наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \nПо этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавим новый столбец для Number of Reviews и запишем туда пропуски, которые встречались в Number of Reviews\ndata['Number of Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Далее заполняем пропуски 0. Скорее всего если отзывов нет, то вместо пропуска должен быть 0.\ndata['Number of Reviews'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Обработка признаков\nДля начала посмотрим какие признаки у нас могут быть категориальными."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Какие признаки можно считать категориальными?"},{"metadata":{},"cell_type":"markdown","source":"Для кодирования категориальных признаков есть множество подходов:\n* Label Encoding\n* One-Hot Encoding\n* Target Encoding\n* Hashing\n\nВыбор кодирования зависит от признака и выбраной модели."},{"metadata":{},"cell_type":"markdown","source":"### City"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Получается, что Ranking имеет нормальное распределение, \n# просто в больших городах больше ресторанов, из-за мы этого имеем смещение\n# необходимо отнормировать критерий Ranking по городам City\nmean_Ranking_on_City = data.groupby(['City'])['Ranking'].mean()\ncount_Restorant_in_City = data['City'].value_counts(ascending=False)\ndata['mean_Ranking_on_City'] = data['City'].apply(lambda x: mean_Ranking_on_City[x])\ndata['count_Restorant_in_City'] = data['City'].apply(lambda x: count_Restorant_in_City[x])\ndata['norm_Ranking_on_Rest_in_City'] = (data['Ranking'] - data['mean_Ranking_on_City']) / data['count_Restorant_in_City']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_Ranking_on_City = data.groupby(['City'])['Ranking'].max()\ndata['max_Ranking_on_City'] = data['City'].apply(lambda x: max_Ranking_on_City[x])\ndata['norm_Ranking_on_maxRank_in_City'] = (data['Ranking'] - data['mean_Ranking_on_City']) / data['max_Ranking_on_City']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\ndata = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Price Range"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По описанию 'Price Range' это - Цены в ресторане.  \nИх можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обработка 'Price Range' - замена по словарю\n\npr_dict = {'$': 1, '$$ - $$$': 2, '$$$$': 3}\n\ndata = data.replace({\"Price Range\": pr_dict})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# А пропуски в 'Price Range' заполним нулями. Предварительно создам создам отдельную колонку и запишу где были пропуски.\ndata['Price Range_isNAN'] = pd.isna(data['Price Range']).astype('uint8')\ndata['Price Range'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### General"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Очищаем данные от мусора. Для начала список строк, которые мне вроде как вообще пока не нужны\ndata = data.drop(['URL_TA', 'ID_TA'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Приведу типы колонок к int, где точно int \ndata = data.astype({\"Price Range\": int,\"Number of Reviews\": int})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cuisine Style"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Для начала создам отдельную колонку и запишу туда все пропуски, которые встречались в Cuisine Style\ndata['Cuisine Style_isNAN'] = pd.isna(data['Cuisine Style']).astype('float64') \n\n# Заполню пропуски значением 'Other' - пусть такие кухни будут в одной категории. \ndata['Cuisine Style'] = data['Cuisine Style'].fillna(\"['Other']\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Формирую новые колонки исходя из кухонь в  Cuisine Style\n\nfrom yaml import safe_load \nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer(sparse_output=True)\n\ntmp = data[\"Cuisine Style\"].dropna().apply(safe_load).dropna()\n\nX = pd.DataFrame.sparse.from_spmatrix(\n        mlb.fit_transform(tmp), \n        columns=mlb.classes_, \n        index=tmp.index)\n\ndata_new = data.join(X, how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_new.iloc[:,46:]\n# Создам отдельную колонку-признак - кол-во кухонь в ресторане\ndata_new[\"Count of Cuisines\"] = data_new.iloc[:,46:].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Думаю, можно уже удалить колонку Cuisine Style\ndata_new = data_new.drop(['Cuisine Style'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Restaurant_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Пока мысли - странно во многих строках данные в Restaurant_id и Ranking визуально как бы коррелируют.\n# Запомним этот момент. Позже гляну на корреляция и если что, то удалю Restaurant_id\n\ndata_new['Restaurant_id_corr_with_Ranking'] = data_new['Restaurant_id'].apply(lambda x: float(x[3:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# С помощью этого я приведу дозаполню пустые места в кухнях и приведу колонки к типу \"число\"\n\ndata_new.iloc[:,42:-2] = np.nan_to_num(data_new.iloc[:,42:-2], nan=0)\ndata_new.iloc[:,42:-2] = data_new.iloc[:,42:-2].fillna(0)\ndata_new.iloc[:,42:-2] = data_new.iloc[:,42:-2].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляю Restaurant_id и Restaurant_id_corr_with_Ranking\ndata_new = data_new.drop(['Restaurant_id', 'Restaurant_id_corr_with_Ranking'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"# В Reviews нет пропусков, но 6471 строк со значением [[], []]. По сути это пустые строки сохраним их \ndata_new['empty_Reviews'] = (data_new['Reviews']=='[[], []]').astype('float64')\n\n# анализ тестовой базы выявил два пропуска, несмотря на то, что pandas.profiling на тренировочной базе пропусков не выявил, заполним их '[[], []]' и закинем в empty_Reviews\ndata_new['Reviews'] = data_new['Reviews'].fillna('[[], []]')\ndata_new['empty_Reviews'] = (data_new['Reviews']=='[[], []]').astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new['date_of_Review'] = data_new['Reviews'].str.findall('\\d+/\\d+/\\d+')\ndata_new['len_date'] = data_new['date_of_Review'].apply(lambda x: len(x))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# есть значение 3 надо разобраться что там\nprint(\"кол-во значений Reviews с тремя датами :=\" , len(data_new[data_new['len_date']==3]))\nprint(\"значения Reviews с тремя датами :=\")\ntemp_list = data_new[data_new['len_date']==3].Reviews.to_list()\ndisplay(data_new[data_new['len_date']==3].Reviews.to_list())\nprint(\"даты после обработки регулярными выражениями:\")\ndisplay([re.findall('\\d+/\\d+/\\d+', x) for x in temp_list])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# видим что люди указывали даты в отзывах и эти даты попали в обработку\n# из-за этого возникнут ошибки так как даты не верные и их формат отличается и формата выгрузки\n# при этом таких строк всего четыре (4), можно было бы их не исправлять а выбросить потому что 17 \n# год явно приведет к выбросу с которым надо будет разбираться. Выбрасывать жалко, тогда исправим,\n# тем более, что это достачно просто\n\ndata_new['len_date'].date_of_Review = data_new[data_new['len_date']==3].date_of_Review.apply(lambda x: x.pop(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# также есть значение 1 надо разобраться что там\nprint(\"кол-во значений Reviews с одной датой :=\" , len(data_new[data_new['len_date']==1]))\ndisplay(data_new[data_new['len_date']==1].Reviews[:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# оказалось, что есть отзывы с одним (1) отзывом и их достаточно много 5680 из (40000-6471) это 17%\n# сохраним это на всякий случай, чтобы не потерять\ndata_new['one_Review'] = (data_new['len_date']==1).astype('float64')\n\n# заполним перерыв между отзывами (по отзывам где len = 2) и насколько давно был сделан последний самый свежий отзыв\n# создадим для этого функции:\ndef time_to_now(row):\n    if row['date_of_Review'] == []:\n        return None\n    return datetime.datetime.now() - pd.to_datetime(row['date_of_Review']).max()\n\ndef time_between_Reviews(row):\n    if row['date_of_Review'] == []:\n        return None\n    return pd.to_datetime(row['date_of_Review']).max() - pd.to_datetime(row['date_of_Review']).min()\n\ndata_new['day_to_now'] = data_new.apply(time_to_now, axis = 1).dt.days\ndata_new['day_between_Reviews'] = data_new[data_new['len_date']==2].apply(time_between_Reviews, axis = 1).dt.days","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Резюме - Reviews: Пропусков в тренировочном датасете нет, в тестовом - 2. Но есть 6471 незаполненных строк с отзывами в тренировочном датасете это 16% от датасета. В 5680 (14%) строках есть только один отзыв, хотя в подавляющем большинстве отзывов два.\nСозданы новые критерии:\n\nempty_Reviews - незаполненные отзывы\ndate_of_Review - даты из отзывов\nlen_date - кол-во дат в отзыве\nday_to_now - насколько давно был сделан последний самый свежий отзыв в днях\nday_between_Reviews - перерыв между отзывами в днях\nРезюме - day_to_now из Reviews: Удаление по порогу не напрашивается так как компания TripAdvisor работает с 2000 года. Максимум 5896/365 ~ 16,5 лет от 2020 года укладывается в дату начала старта сайта. В выбросы попало 2365 (почти 6%) значений, с учетом резюме по неполным данным в критерии Reviews, я пока принимаю решение не избавлятся от выросов, построить модель, обратить внимание на важность критерия, и при необходимости вернуться к нему для заполнения парсингом или удаления выбросов"},{"metadata":{"trusted":true},"cell_type":"code","source":"# кол-во выбросов 495 (1.2%) - это статистически не значимо, но мы пока сохраняем информацию о выбросе, а потом проверим его важность в модели\ndata_new['out_day_between_Reviews'] = (data_new['day_between_Reviews']==0).astype('float64')\n\n# и удаляем выбросы\ndata_new.loc[data_new['day_between_Reviews']==0, 'day_between_Reviews'] = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Резюме - day_between_Reviews из Reviews: Заполнен слабо 70%. Удалены выбросы в нуле (492 значения). Создан новый критерий - out_day_between_Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"# в переменной 2543 (6.4%) пропущенных значений \n# сохраним эту информацию\ndata_new['Number of Reviews_NAN'] = pd.isna(data_new['Number of Reviews']).astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# выбросов не так много, удалим их, предварительно сохранив информацию о них\ndata_new['outliers_Number of Reviews'] = pd.DataFrame(data_new['Number of Reviews']>5252).astype('float64')\ndata_new.loc[data_new['Number of Reviews']>5252, 'Number of Reviews']=None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Резюме - Number of Reviews 2543 (6.4%) пропусков."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.select_dtypes(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удалим оставшиеся object строки\ndata_new = data_new.drop(['Reviews', 'date_of_Review'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\ndef applyFeatures(dataset):\n\n    columns = dataset.columns.tolist()\n    target = columns[4]\n    columns.remove(target)\n    \n    \n    for c in columns:\n        dataset[c] = scaler.fit_transform(dataset[c].values.reshape(-1, 1))\n    \n        \napplyFeatures(data_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #MinMax Normalization not running for this algorithm\n\n    from sklearn.preprocessing import MinMaxScaler\n\n    scaler = MinMaxScaler()\n    data_new[['Ranking']] = scaler.fit_transform(data_new[['Ranking']])\n\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на корреляция между Restaurant_id и ranking"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Корреляция между Ranking и Restaurant_id_corr_with_Ranking достаточно большая. Принимаю решение удалить Restaurant_id_corr_with_Ranking и следовательно Restaurant_id"},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение признака"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['City'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение."},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной относительно признака"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### И один из моих любимых - [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\nНа этом графике уже сейчас вы сможете заметить, как признаки связаны между собой и с целевой переменной."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data_new.drop(['sample'], axis=1).corr(),)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вообще благодаря визуализации в этом датасете можно узнать много интересных фактов, например:\n* где больше Пицерий в Мадриде или Лондоне?\n* в каком городе кухня ресторанов более разнообразна?\n\nпридумайте свои вопрос и найдите на него ответ в данных)"},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."},{"metadata":{"trusted":true},"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка ############################################################## \n    \n    \n    # Заполню это позже когда отработаю до конца все.\n   \n    \n    # ################### 7. Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    \n    return df_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). "},{"metadata":{},"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = data_new.query('sample == 1.0').drop(['sample'], axis=1)\ntest_data = data_new.query('sample == 0.0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What's next?\nИли что делать, чтоб улучшить результат:\n* Обработать оставшиеся признаки в понятный для машины формат\n* Посмотреть, что еще можно извлечь из признаков\n* Сгенерировать новые признаки\n* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n* Подобрать состав признаков\n\nВ общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}